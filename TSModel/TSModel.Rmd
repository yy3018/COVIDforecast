---
title: "TSModel"
author: "Yiling Yang"
output: pdf_document
---

```{r,message=FALSE}
# Library Import
library(tidyverse)
library(forecast)
library(lubridate)
library(tseries)
library(kableExtra)
```

```{r,message=FALSE}
# Data Import
covid <- read_csv("C:/Users/Yiling Yang/Desktop/school_work/Project/COVIDforecast/data/data-yqfdF.csv")
covid$DATE_OF_INTEREST <-  as.Date(parse_date_time(covid$DATE_OF_INTEREST,
                            guess_formats(
                              as.character(covid$DATE_OF_INTEREST), c("mdy", "dmy", "dmY")
                            )))

covid <- covid %>% rename(Date = DATE_OF_INTEREST) %>% select(Date,Cases)
```


# Introduction

This is a personal project aimming to forecast the future daily confirmed cases of COVID-19 based on historical data from 3/15/2020 to 7/15/2020. The Project consists of two parts: 1) Forecast with Time Seris Model, ARMA and ARIMA, and 2) forecast with LSTM and 1-D CNN neural network. The LSTM neural network part will be done in Python. This markdown is particular for the first part. 

# Exploratory Data Analysis

To fit time series model, we usually need to make sure the stationary assumption held. I will perform 3 ways to check it: 1) Plot the time series, 2) Plot the ACF, and 3) Run ADF test.

## 1. Data at glance

```{r}
ggplot(covid,aes(x=Date,y=Cases)) + geom_line()
```

The data are not bounded very well, which might imply non-stationary.

## 2. ACF
```{r}
ggAcf(covid$Cases,type="correlation")
```

The autocorrelation graph also shows a slow decreasing of the autocorrelation coefficient. This can also be a sign of non-stationary.

## 3. Augmented Dickey-Fuller Test
```{r}
adf.test(covid$Cases)
```


The ADF test output confirms with previous two chunks' output that the data is highly likely not stationary. We then might need transform it through differencing or detrending. Fortunately, the auto.arima function will help us achieve that.

# Model Fitting

In this section, I will fit various time series model. For all of them, I will train them with the first 120 day as the training dataset, about 85 percent of the dataset with the use of AIC as the metric. And then, to compare with neural networks from the second part, I will record the mean square error of the validation set, which are the latest 20 observations.

## ARMA

The Autoregressiveâ€“moving-average (ARMA) model combines the use of Moving Average (MA) and Autoregressive (AR) model. The equation can be written as:

$$X_t = c+\epsilon_t+\sum_{i=1}^p\beta_iX_t-i+\sum_{i=1}^p\theta_i\epsilon_t-i$$

where c is a constant.

```{r}
arma.model <- auto.arima(covid$Cases[1:130],max.d = 0,allowdrift = T)
arma.model
```

As the output shown, the chosen ARMA model is ARMA(2,3) with AIC 1852.83.

## ARIMA

The difference between ARMA and ARIMA is that ARIMA allows for measure of how many nonseasonaldifferences are needed to achieve stationarity.
```{r}
arima.model <- auto.arima(covid$Cases[1:120],allowdrift = T)
arima.model
```

As the output shown, the ARIMA(2,1,3) was chosen with AIC of 1837.27.

## Validation

To compare with the neural networks, I will then do a forecast of next 41 days' data, and record their MSE. For demostration, I include the corresponding graphs for both two models.

```{r}
arma.forecast <- forecast(arma.model,h=20)
arima.forecast <- forecast(arima.model,h=20)

autoplot(arma.forecast)
autoplot(arima.forecast)
```

```{r}
kable(data.frame(
  model = c("ARMA","ARIMA"),
  MSE = c(mean((covid$Cases[121:140] - arma.forecast$mean)**2),
mean((covid$Cases[121:140] - arima.forecast$mean)**2))
))
```

As the table shown above, the ARIMA(2,1,3) outperforms the ARMA(2,3) model. I will then step into the second part of this project, fitting LSTM CNN neural network.



